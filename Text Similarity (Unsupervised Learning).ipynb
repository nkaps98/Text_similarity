{"cells":[{"metadata":{},"cell_type":"markdown","source":"The data contains a pair of paragraphs. These text paragraphs are randomly sampled from a raw dataset. Each pair of the sentence may or may not be semantically similar. The dataset considered for this project does not contain any labels. Given below is the solution to the unsupervised machine learning problem","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nimport re\nimport scipy\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom gensim.models import Word2Vec, KeyedVectors, FastText\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Embedding, Flatten, SimpleRNN, RNN,GRU, SpatialDropout1D, Dropout\nfrom keras.preprocessing.sequence import pad_sequences\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/Text_Similarity_Dataset.csv')\ndata.shape #(4023,3)\n\nX = data.iloc[:,1:].values\ns1 = X[:,0]\ns2 = X[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s1 = ['What is the step by step guide to invest in share market in india?',\n'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n'How can I increase the speed of my internet connection while using a VPN?',\n'Why am I mentally very lonely? How can I solve it?',\n'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?',\n'Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?',\n'Should I buy tiago?',\n'How can I be a good geologist?',\n'When do you use ã‚· instead of ã—?',\n'Motorola (company): Can I hack my Charter Motorolla DCX3400?',\n'Method to find separation of slits using fresnel biprism?',\n'How do I read and find my YouTube comments?',\n'What can make Physics easy to learn?',\n'What was your first sexual experience like?',\n'What are the laws to change your status from a student visa to a green card in the US, how do they compare to the immigration laws in Canada?',\n'What would a Trump presidency mean for current international masterâ€™s students on an F1 visa?']\n\ns2 = ['What is the step by step guide to invest in share market?',\n'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?',\n'How can Internet speed be increased by hacking through DNS?',\n'Find the remainder when [math]23^{24}[/math] is divided by 24,23?',\n'Which fish would survive in salt water?',\n\"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\",\n'What keeps childern active and far from phone and video games?',\n'What should I do to be a great geologist?',\n'When do you use \"&\" instead of \"and\"?',\n'How do I hack Motorola DCX3400 for free internet?',\n'What are some of the things technicians can tell about the durability and reliability of Laptops and its components?',\n'How can I see all my Youtube comments?',\n'How can you make physics easy to learn?',\n'What was your first sexual experience?',\n'What are the laws to change your status from a student visa to a green card in the US? How do they compare to the immigration laws in Japan?',\n'How will a Trump presidency affect the students presently in US or planning to study in US?'\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing of Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tokens1 = []\ntokens2 = []\ntokens1 = [word_tokenize(str(sentence)) for sentence in s1]\ntokens2 = [word_tokenize(str(sentence)) for sentence in s2]\n\nrm1 = []\nfor w in tokens1:\n    sm = re.sub('[^A-Za-z]',' ', str(w))\n    x = re.split(\"\\s\", sm)\n    rm1.append(x)\n    \nrm2 = []\nfor w in tokens2:\n    sm2 = re.sub('[^A-Za-z]',' ',str(w))\n    x2 = re.split(\"/s\",sm2)\n    rm2.append(x2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing whitespaces    \nfor sent in rm1:\n    while '' in sent:\n        sent.remove('')\n\nfor sent in rm2:\n    while '' in sent:\n        sent.remove('')\n        \n# Lowercasing\nlow1 = []\nfor i in rm1:\n    i = [x.lower() for x in i]\n    low1.append(i)\n\nlow2 = []\nfor i in rm2:\n    i = [x.lower() for x in i]\n    low2.append(i)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lemmatozation\nlemma1 = []\nwnl = WordNetLemmatizer()\nfor sent in low1:\n    tokens = [wnl.lemmatize(w) for w in sent]\n    lemma1.append(tokens)\n    \nlemma2 = []\nfor sent in low2:\n    tok = [wnl.lemmatize(se) for se in sent]\n    lemma2.append(tok)\n    \n# Removing Stopwords\nfilter_words1 = []\nStopwords = set(stopwords.words('english'))\n\nfor sent in lemma1:\n    tokens = [w for w in sent if w not in Stopwords]\n    filter_words1.append(tokens)\n    \nfilter_words2 = []\nfor sent in lemma2:\n    tokens2 = [w for w in sent if w not in Stopwords]\n    filter_words2.append(tokens2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FastText\nFastText is an extension to Word2Vec proposed by Facebook in 2016. Instead of feeding individual words into the Neural Network, FastText breaks words into several n-grams (sub-words). For instance, the tri-grams for the word apple is app, ppl, and ple (ignoring the starting and ending of boundaries of words). The word embedding vector for apple will be the sum of all these n-grams. After training the Neural Network, we will have word embeddings for all the n-grams given the training dataset. Rare words can now be properly represented since it is highly likely that some of their n-grams also appears in other words.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = FastText('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz')\nword_vectors = model.wv\nvocabulary = word_vectors.vocab.items()\nsimilarity = word_vectors.similarity('woman', 'man')\n\ndef cosine_similarity_bw_two_words(word1,word2):\n    return word_vectors.similarity(word1,word2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cosine Similarity\nCosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. The cosine of 0° is 1, and it is less than 1 for any angle in the interval (0, π] radians.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"result = []\nwmd = []\nfor sent1, sent2 in zip(filter_words1,filter_words2):\n    print(sent1)\n    print(sent2)\n    vector1 = np.mean([model[word] for word in sent1], axis = 0)\n    vector2 = np.mean([model[word] for word in sent2], axis = 0)\n    cosine = scipy.spatial.distance.cosine(vector1, vector2)\n    result.append((1-cosine))\n    wmd.append(model.wmdistance(sent1,sent2))\n#data['Result[%]'] = result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wmd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sort_values([\"Result[%]\"], axis=0, \n                 ascending=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}